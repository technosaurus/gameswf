GENERAL

* Try quantizing down to 8 bits/coordinate.

  -- Tried it; it doesn't work well.  Creates intolerable quantization
  error on the island_4k dataset, and probably others if you look
  closely.

* Streaming.  The fundamentals are in place.  The obstacles are the
  details.  It would be nice to memory-map the chunk file, and stream
  verts directly out of it; that should make best use of the OS (and
  give a quicker startup time).  Unfortunately that means the
  streaming will have to take care of endian-ness of the data, so
  big-endian platforms may require custom code in order to get full
  performance.  Also the chunk linking will need some work; the
  chunker will probably need to write a "table of contents", with file
  offsets for all the chunks.  For truly big datasets I'll need to
  deal more carefully with the chunk nodes themselves; possibly
  allocating only on demand, like in the adaptive quadtree stuff.

* Selective LOD.  This is a compression approach where less detail is
  used in areas that it's known that the viewpoint will stay far away
  from.  Like in Soul Ride, and my adaptive quadtree demo.  This is
  mostly be a matter of describing the desired LOD info to the
  chunker.

* Texture LOD (straightforward implementation is trivial; the problem
  is dealing with massive data, so a good demo depends on streaming,
  or selective LOD).


HEIGHTFIELD CHUNKER

* automatically determine a good tree depth.

* support multiple input datasets at different resolutions, and be
  able to specify variable LOD.

* georeferencing?

* localized, bottom up processing?  more VM friendly; try a swizzled
  format?  Generally make the chunking process quicker.


CHUNKDEMO

* command-line switches for window dimensions.

* Need a fence/sync for the vertex stream buffer!  Occasionally the
  stream will eat its own tail and render garbage.  I think this is
  just a matter of digging through OpenGL API docs.

* try a vertex shader for lerping.  (NOTE: The demo can someimes
  achieve near-maximum triangle throughput on my 1GHz machine, even
  with the substantial per-vertex CPU processing that goes on during
  streaming, so the vertex shader may not be worth it for apps that
  aren't CPU limited.)

* paging/streaming off disk.

* No collision-detection right now!  The chunk data is render-friendly
  but collision-query unfriendly.  The options as I see it are:

  1) Implement some kind of indexing acceleration structure, to direct
     collision queries to the appropriate faces in the vertex data.  A
     grid of lists would probably be fine.  This isn't too bad,
     possibly.  I'm pretty sure it'll have substandard speed for
     queries, but maybe not too bad.  I think this is what John
     Ratcliff once said he was doing for Planetside.

  2) Use separate collision info.  Perhaps use a compressed linear
     quadtree per chunk; these should use a small fraction of the
     render data size, give quick queries, and allow different
     representation of collidable and visible (e.g. for some games you
     may not need any collide geometry at all in large inaccessible
     areas; for a flight sim maybe you only need low-res collision
     data).  Also you can easily encode surface-type data in an
     alternate representation.

* Doll it up with a skydome, fog, trees, etc.

* Make a fun game :)


HEIGHTFIELD SHADER

* This thing is basically one big hack at the moment.  It's not fast,
  nor is it flexible.

* Use Lua configuration to specify shaders.  Would be nice to do the
  standard tricks, like choose a surface based on slope & altitude.

* Noise, blending, or other techniques at tile boundaries.

* Better lighting, with shadows, and possibly some crude secondary
  lighting.
