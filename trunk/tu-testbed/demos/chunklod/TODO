GENERAL

* Try using strips!  I bet this is the limiting factor on triangle
  rate right now, on GeForce-family hardware.  The chunks are
  generated by a BTT-style optimizer, so very good strips should fall
  right out without much trouble.  This should save some index RAM
  too.


HEIGHTFIELD CHUNKER

* There's a lurking lerping bug; occasionally a bottom-level vert will
  pop.  I'm pretty sure this is in the chunker, not the renderer.

* My t-junction crack-filling meshes, generated on the fly by the
  renderer, are mostly functional at the moment, but ad hoc and
  sometimes horrible.  Occasionally a crack shows, too.  Really what's
  needed is a proper tesselator in heightfield_chunker to look at the
  crack polygon and pre-compute the correct faces.  Actually should be
  very simple.  The difficulty is that the verts currently come from
  different vertex arrays.  There are two solutions, 1) allocate all
  the verts for the entire heightfield from one array, and 2)
  duplicate the child-edge verts in the parent edge vertex array.  1)
  is simple and effective, but unacceptable because it inhibits
  paging.  The whole point of LOD in this day and age is to enable
  view-dependent paging of tons of detail.  So 2) is the way to go;
  even though it wastes some RAM, it will win big in the end.

  On second thought, paging will require some app-level memory
  management to deal with the vertex RAM.  So maybe by doing that at
  the vertex level, there are some available tricks to make option 1
  feasible.

* support multiple input datasets at different resolutions, &
  georeferencing.

* localized, bottom up processing?  more VM friendly; try a swizzled
  format?  Ultimately we want to be able to batch process giant
  datasets, much bigger than will fit in RAM.


CHUNKDEMO

* download some bigger data, process it & see what happens

* try a vertex shader for lerping.  (NOTE: CPU morphing has *zero*
  impact on the performance of the demo on my laptop w/ 1GHz CPU and
  GeForce2Go, so the vertex shader may not be worth it for apps that
  aren't CPU limited.)  (Could possibly *hurt* performance in the
  demo?  I.e. we're currently getting nice parallelism?  But in a game
  you want the CPU for other stuff too.)

* paging

* No collision-detection right now!  The chunk data is render-friendly
  but collision-query unfriendly.  The options as I see it are:

  1) Implement some kind of indexing acceleration structure, to direct
     collision queries to the appropriate faces in the vertex data.  A
     grid of lists would probably be fine.  This isn't too bad,
     possibly.  I'm pretty sure it'll have substandard speed for
     queries, but maybe not too bad.  I think this is what John
     Ratcliff said he was doing for Planetside.

  2) Use separate collision info.  Perhaps use a compressed linear
     quadtree per chunk; these should use a small fraction of the
     render data size, give quick queries, and allow different
     representation of collidable and visible (e.g. for some games you
     may not need any collide geometry at all in large inaccessible
     areas; for a flight sim maybe you only need low-res collision
     data).  Also you can easily encode surface-type data in an
     alternate representation.
